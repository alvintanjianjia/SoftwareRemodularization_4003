{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from zipfile import ZipFile\n",
    "from filecmp import dircmp\n",
    "\n",
    "### Change project name here ####\n",
    "project_names = ['alibaba-fastjson', 'activiti-activiti',\n",
    "                'androidannotations-androidannotations',\n",
    "                 'bumptech-glide',\n",
    "                 'checkstyle-checkstyle',\n",
    "                 'codecentric-spring-boot-admin',\n",
    "                 'dropwizard-dropwizard',\n",
    "                 'dropwizard-metrics',\n",
    "                 'evant-gradle-retrolambda',\n",
    "                 'facebook-facebook-android-sdk',\n",
    "                 'facebook-buck',\n",
    "                 'facebook-litho',\n",
    "                 'google-dagger',\n",
    "                 'google-error-prone',\n",
    "                 'google-exoplayer.csv',\n",
    "                 'grpc-grpc-java',\n",
    "                 'jakewharton-butterknife',\n",
    "                 'java-native-accessjna',\n",
    "                 'jenkinsci-jenkins',\n",
    "                 'jhy-jsoup',\n",
    "                 'mockito-mockito',\n",
    "                 'mybatis-mybatis-3',\n",
    "                 'naver-pinpoint',\n",
    "                 'permissions-dispatcher-PermissionsDispatcher',\n",
    "                 'prolificinteractive-material-calendarview',\n",
    "                 'pxb1988-dex2jar',\n",
    "                 'ReactiveX-RxJava',\n",
    "                 'realm-realm-java',\n",
    "                 'redisson-redisson',\n",
    "                 'swagger-api-swagger-core'\n",
    "\n",
    "                ]\n",
    "\n",
    "n_clusters = [50,100,150,200,250,300]\n",
    "affinity = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "linkage = ['complete', 'average', 'single']\n",
    "\n",
    "\n",
    "### Uncomment below for testing purposes ###\n",
    "#n_clusters = [50]\n",
    "#affinity = ['euclidean']\n",
    "#linkage = ['complete']\n",
    "\n",
    "\n",
    "def alvin_god(user_n_cluster, user_affinity, user_linkage, dir_arr, depends_arr, file_version, main_dict):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(dir_arr)\n",
    "\n",
    "    true_k = user_n_cluster\n",
    "    model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "    model.fit(X)\n",
    "\n",
    "    #print(\"Top terms per cluster:\")\n",
    "    order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    \n",
    "    main_cluster_arr = []\n",
    "    col_counter = 0\n",
    "\n",
    "    \n",
    "    cluster = AgglomerativeClustering(n_clusters=user_n_cluster, affinity=user_affinity, linkage=user_linkage)\n",
    "    cluster_result = cluster.fit_predict(depends_arr)\n",
    "\n",
    "    cluster_result_arr = []\n",
    "    cluster_counter = 0\n",
    "    for element in cluster_result:\n",
    "        #print(element)\n",
    "        cluster_result_arr.append(element)\n",
    "\n",
    "    main_cluster_arr.append(cluster_result_arr)\n",
    "    \n",
    "    col_counter += 1\n",
    "    \n",
    "    dir_arr_int = []\n",
    "    #for element in dir_arr:\n",
    "    #    dir_arr_int.append(main_dict[element])\n",
    "    \n",
    "    #cluster_result_int = []\n",
    "    #for element in cluster_result:\n",
    "        #cluster_result_int.append(main_dict[main_dict_val[element]])\n",
    "    \n",
    "    #print(dir_arr_int)\n",
    "    #print('fk')\n",
    "    #print(cluster_result_int)\n",
    "    #common_results_rsf = common_member(dir_arr_int,cluster_result_int)\n",
    "    #print(len(common_results_rsf))\n",
    "    \n",
    "    \n",
    "    filename1 = 'MoJo_1.2.1/' + project_name + '/' +str(file_version) + '_' + str(user_n_cluster) + '_' + str(user_affinity) + \"_\" + str(user_linkage) + '_b' +\".rsf\"\n",
    "    #print(filename1)\n",
    "    with open(filename1, 'w') as f:\n",
    "        for i in range(len(dir_arr)):\n",
    "            Y = vectorizer.transform([dir_arr[i]])\n",
    "            string = \"contain \" + str(model.predict(Y)[0]) + \" \" +str(i) + \"\\n\"\n",
    "            f.write(string)\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    filename2 = 'MoJo_1.2.1/' + project_name + '/' +str(file_version) + '_' + str(user_n_cluster) + '_' + str(user_affinity) + \"_\" + str(user_linkage) + '_a' +\".rsf\"\n",
    "    with open(filename2, 'w') as f:\n",
    "        for i in range(len(cluster_result)):\n",
    "            #print(element)\n",
    "            string = \"contain \" + str(cluster_result[i]) + \" \" + str(i) + \"\\n\"\n",
    "            f.write(string)\n",
    "        f.close()\n",
    "        #for element in cluster_result:\n",
    "            #print(element)\n",
    "            #string = \"contain \" + str(element) + \" \" + str(main_dict[main_dict_val[element]]) + \"\\n\"\n",
    "            #f.write(string)\n",
    "        #f.close()\n",
    "\n",
    "    #print('Difference is: ' + str(len(dir_arr) - len(G.nodes) ))\n",
    "    if len(dir_arr) - len(G.nodes) > 0:\n",
    "        with open(filename2,'a') as f:\n",
    "            for i in range(len(dir_arr)-len(G.nodes)):\n",
    "                tbc = (i+len(G.nodes))\n",
    "                string = \"contain \" + str(tbc) + \" \" + str(tbc) + \"\\n\"\n",
    "                f.write(string)\n",
    "\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename1,'a') as f:\n",
    "            for i in range(len(G.nodes) - len(dir_arr)):\n",
    "                tbc = i+len(dir_arr)\n",
    "                string = \"contain \" + str(tbc) + \" \" + str(tbc) + \"\\n\"\n",
    "                f.write(string)\n",
    "            f.close()\n",
    "\n",
    "    return filename1, filename2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fileIsSame(right, left, path):\n",
    "    return os.path.exists (os.path.join(left, path.replace(right, '')));\n",
    "\n",
    "def compare(right, left):\n",
    "    difference = list();\n",
    "    for root, dirs, files in os.walk(right):\n",
    "        for name in files:\n",
    "            path = os.path.join(root, name);\n",
    "            # check if file is same\n",
    "            if fileIsSame(right, left, path):\n",
    "                if os.path.isdir(path):\n",
    "                    # recursively check subdirs\n",
    "                    difference.extend(compare(path, left));\n",
    "            else:\n",
    "                # count file as difference\n",
    "                difference.append(path);\n",
    "\n",
    "    return difference;\n",
    "\n",
    "def compare_similar(right, left):\n",
    "    difference = list();\n",
    "    for root, dirs, files in os.walk(right):\n",
    "        for name in files:\n",
    "            path = os.path.join(root, name);\n",
    "            # check if file is same\n",
    "            if fileIsSame(right, left, path):\n",
    "                \n",
    "                if os.path.isdir(path):\n",
    "                    # recursively check subdirs\n",
    "                    difference.extend(compare_similar(path, left));\n",
    "                difference.append(path)\n",
    "                \n",
    "            #else:\n",
    "                # count file as difference\n",
    "                #difference.append(path);\n",
    "\n",
    "    return difference;\n",
    "\n",
    "\n",
    "\n",
    "def common_member(a,b):\n",
    "    a_set = set(a)\n",
    "    b_set = set(b)\n",
    "    if len(a_set.intersection(b_set)) > 0:\n",
    "        return(a_set.intersection(b_set))\n",
    "    else:\n",
    "        return set()\n",
    "  \n",
    "\n",
    "\n",
    "for project_name in project_names:\n",
    "    try:\n",
    "        f = open('project_list.txt', 'a')\n",
    "        to_write = project_name + '\\n'\n",
    "        f.write(to_write)\n",
    "        f.close()\n",
    "\n",
    "        ver = pd.read_csv(project_name + '.csv', encoding='ISO-8859-1')\n",
    "        ver.head()\n",
    "\n",
    "        release_arr = []\n",
    "\n",
    "        link = open(project_name + '.txt')\n",
    "        for line in link:\n",
    "            link_str = line\n",
    "\n",
    "        link.close()\n",
    "\n",
    "\n",
    "        os.mkdir('C:/Users/user/Desktop/FIT4003/raw_sourcecode/' + project_name)\n",
    "\n",
    "        for index, row in ver.iterrows():\n",
    "            #print(index)\n",
    "            #print('lol')\n",
    "            #print(row['release_tag'])\n",
    "            release_arr.append((row['release_tag'], row['version_name']))\n",
    "\n",
    "        for element in release_arr:\n",
    "            command = 'cd C:/Users/user/Desktop/FIT4003/raw_sourcecode/' + project_name + ' & mkdir ' + project_name + '-' + element[1]\n",
    "            #print(command)\n",
    "            os.system(command)\n",
    "\n",
    "            command = 'git clone ' + link_str +  ' C:/Users/user/Desktop/FIT4003/raw_sourcecode/' + project_name + '/' + project_name + '-' +element[1]\n",
    "            #print(command)\n",
    "            os.system(command)\n",
    "\n",
    "            command = 'cd C:/Users/user/Desktop/FIT4003/raw_sourcecode/' + project_name + '/' + project_name +'-' + element[1] + ' & git checkout ' + element[0]\n",
    "            #print(command)\n",
    "            os.system(command)\n",
    "\n",
    "\n",
    "        rootdir = 'raw_sourcecode'\n",
    "        dir_arr = []\n",
    "        rootdir_arr = []\n",
    "        depth=2\n",
    "\n",
    "        for root, dirs, files in os.walk(rootdir):\n",
    "            if root.count(os.sep) == depth and project_name in str(root):\n",
    "                #print(root)\n",
    "                dir_arr.append(root)\n",
    "                rootdir_arr.append(root)\n",
    "                #for file in files: \n",
    "                    #print(os.path.join(subdir, file))\n",
    "                ### Only look for Java Files ###\n",
    "                #if \"Apache Spark versions\" in str(os.path.join(subdir, file)):\n",
    "                    #print(os.path.join(subdir, file))\n",
    "\n",
    "                    #dir_arr.append(str(os.path.join(subdir, file)))\n",
    "\n",
    "        #print(len(dir_arr))\n",
    "\n",
    "\n",
    "        os.mkdir('MoJo_1.2.1/' + project_name)\n",
    "        os.mkdir('raw_depends/' + project_name)\n",
    "        for i in range(len(dir_arr)):\n",
    "            #print(element)\n",
    "            command = 'cd C:/Users/user/Desktop/FIT4003/depends-0.9.2 & ' + 'java -jar depends.jar java C:/Users/user/Desktop/FIT4003/raw_sourcecode/'  + project_name + '/' + dir_arr[i].split('\\\\')[-1] +  ' ../raw_depends/' + project_name + '/' + str(i) + '_' + dir_arr[i].split('\\\\')[-1] \n",
    "            #print(command)\n",
    "            #os.system('cd C:/Users/user/Desktop/FIT4003/MoJo_1.2.1 & java MoJo test/test2_a.rsf test/test2_b.rsf > test/test_results.txt')\n",
    "            os.system(command)\n",
    "\n",
    "        rootdir = 'raw_depends/' + project_name\n",
    "        json_name_dict = {}\n",
    "        json_result_dict = {}\n",
    "        for root, dirs, files in os.walk(rootdir):\n",
    "\n",
    "            #print(files)\n",
    "            for element in files:\n",
    "\n",
    "                with open(rootdir + '/' + element) as f:\n",
    "                    tmp = json.load(f)\n",
    "\n",
    "                element = element.split('_')\n",
    "                json_name_dict[element[0]] = element[1]\n",
    "                json_result_dict[element[0]] = tmp\n",
    "\n",
    "        ### Getting the ground truth by comparing previous 10 versions (Burden AF)\n",
    "        ground_truth_dict = {}\n",
    "        max_len_tmp = 0\n",
    "        root_dir = 'raw_sourcecode/' + project_name + '/'\n",
    "        for i in range(10,20):\n",
    "            file1 = str(root_dir +json_name_dict[str(i)]).replace('.json', '') + '/'\n",
    "            for j in range(1,11):\n",
    "                file2 = str(root_dir + json_name_dict[str(i-j)]).replace('.json', '') + '/'\n",
    "\n",
    "                #test = compare_similar()\n",
    "                #print(file1, file2)\n",
    "                if (j == 1):\n",
    "                    prev_tmp = compare_similar(file1, file2)\n",
    "                else:\n",
    "                    tmp = compare_similar(file1, file2)\n",
    "                    tmp = common_member(prev_tmp, tmp)\n",
    "                    #print(len(tmp))\n",
    "                    prev_tmp = tmp\n",
    "\n",
    "            if len(prev_tmp) > max_len_tmp:\n",
    "                max_len_tmp = len(prev_tmp)\n",
    "            #print(len(prev_tmp))\n",
    "            ground_truth_dict[str(i)] = prev_tmp\n",
    "\n",
    "\n",
    "        for i in range(len(ground_truth_dict)):\n",
    "            #print(i)\n",
    "            dir_arr = []\n",
    "            for element in ground_truth_dict[str(i+10)]:\n",
    "                if \".java\" in element:\n",
    "                    element = element.replace('\\\\', '/')\n",
    "                    element = element.replace('raw_sourcecode/' + project_name + '/' + json_name_dict[str(i+10)].split('.json')[0] + '/', '' )\n",
    "                    element = element.replace('/', '\\\\')\n",
    "                    element = '\\\\' + element\n",
    "                    dir_arr.append(element)\n",
    "\n",
    "            #print('raw_depends/apache_log4j/' + str(i+10)+ '_'+ json_name_dict[str(i+10)])\n",
    "            with open('raw_depends/' + project_name + '/' + str(i+10)+ '_'+ json_name_dict[str(i+10)]) as f:\n",
    "                spark_results = json.load(f)\n",
    "\n",
    "            main_dict = {}\n",
    "            main_dict_val = {}\n",
    "            main_dict_counter = 0\n",
    "            dict_array = []\n",
    "            min_set = set()\n",
    "            for element in spark_results['variables']:\n",
    "                #print(element)\n",
    "\n",
    "                ### Replace this with the initial JSON directory ###\n",
    "                #print(json_name_dict[str(i+10)])\n",
    "                element_tbc = element.replace('C:\\\\Users\\\\user\\\\Desktop\\\\FIT4003\\\\raw_sourcecode\\\\' + project_name + '\\\\' +json_name_dict[str(i+10)].split('.json')[0] , '')\n",
    "                #print(element)\n",
    "                main_dict[element_tbc] = main_dict_counter\n",
    "                main_dict_val[main_dict_counter] = element_tbc\n",
    "                main_dict_counter += 1\n",
    "\n",
    "\n",
    "            index  = 0\n",
    "            var_array = []\n",
    "            for value in spark_results['variables']:\n",
    "                var_array.append([index, value])\n",
    "                #print(index, value)\n",
    "                index += 1\n",
    "\n",
    "            var_df = pd.DataFrame(var_array)\n",
    "            var_df.columns = ['index_val', 'name']\n",
    "\n",
    "            feature_list = {}\n",
    "            feature_index = 2\n",
    "            for element in spark_results['cells']:\n",
    "                #print(element)\n",
    "                try:\n",
    "                    for a in element['values']:\n",
    "                        if a not in feature_list:\n",
    "                            feature_list[a] = feature_index\n",
    "                            feature_index += 1\n",
    "                        #print(a['Call'])\n",
    "\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            feature_arr = []\n",
    "            for element in spark_results['cells']:\n",
    "                #print(array)\n",
    "                array = [0] * (len(feature_list) + 2)\n",
    "                values = dict(element['values'])\n",
    "                #print(element)\n",
    "                array[0] = element['src']\n",
    "                array[1] = element['dest']\n",
    "                for feature in feature_list:\n",
    "                    try:\n",
    "                        value = values[feature]\n",
    "                        array[feature_list[feature]] = value\n",
    "                    except:\n",
    "                        pass\n",
    "                #print(array)\n",
    "                feature_arr.append(array)\n",
    "\n",
    "            feature_df = pd.DataFrame(feature_arr)\n",
    "            col_names = ['src', 'dest']\n",
    "            for element in feature_list:\n",
    "                col_names.append(element)\n",
    "            feature_df.columns = col_names\n",
    "\n",
    "            feature_df['sum'] = feature_df.sum(axis=1) - feature_df['src'] - feature_df['dest']\n",
    "            G = nx.Graph()\n",
    "            for index, row in feature_df.iterrows():\n",
    "                G.add_edge(row['src'], row['dest'], weight=row['sum'])\n",
    "\n",
    "            adj_mat = nx.adjacency_matrix(G)\n",
    "            adj_mat_df = pd.DataFrame(adj_mat.todense())\n",
    "            np.fill_diagonal(adj_mat_df.values, adj_mat_df.values.max())\n",
    "            x = adj_mat_df.values\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "            x_scaled = min_max_scaler.fit_transform(x)\n",
    "            adj_mat_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "            #os.mkdir('MoJo_1.2.1/' + project_name)\n",
    "\n",
    "            filename_arr = []\n",
    "            for number in n_clusters:\n",
    "                for affinity_type in affinity:\n",
    "                    for linkage_type in linkage :\n",
    "                        try:\n",
    "                            filename_1, filename_2 = alvin_god(number, affinity_type, linkage_type, dir_arr, adj_mat_df, json_name_dict[str(i+10)].split('.json')[0], main_dict)\n",
    "                            filename_1 = filename_1.replace('MoJo_1.2.1/', '')\n",
    "                            filename_2 = filename_2.replace('MoJo_1.2.1/', '')\n",
    "                            filename_arr.append((filename_1, filename_2))\n",
    "                            #print(filename_1, filename_2)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "\n",
    "            for i in range(len(filename_arr)):\n",
    "\n",
    "                command = 'cd C:/Users/user/Desktop/FIT4003/MoJo_1.2.1 & ' + 'java MoJo ' + filename_arr[i][1] + ' ' + filename_arr[i][0] + ' >> ' + project_name + '/' + project_name + '_results.txt'\n",
    "                #print(command)\n",
    "                #os.system('cd C:/Users/user/Desktop/FIT4003/MoJo_1.2.1 & java MoJo test/test2_a.rsf test/test2_b.rsf > test/test_results.txt')\n",
    "                os.system(command)\n",
    "\n",
    "\n",
    "\n",
    "        os.mkdir('Final_Results/' + project_name)\n",
    "        for i in range(11,21):\n",
    "            #print(rootdir_arr[i])\n",
    "            command = 'cd C:/Users/user/Desktop/FIT4003/ & ' + 'java -jar ck-0.3.3-SNAPSHOT-jar-with-dependencies.jar ' + rootdir_arr[i]\n",
    "            #print(command)\n",
    "            os.system(command)\n",
    "            import shutil\n",
    "            #os.mkdir('Final_Results/' + project_name)\n",
    "            os.rename('class.csv', project_name + '-' + rootdir_arr[i].split('\\\\')[-1] +  '_class.csv')\n",
    "            os.rename('field.csv', project_name + '-' + rootdir_arr[i].split('\\\\')[-1] + '_field.csv')\n",
    "            os.rename('method.csv', project_name + '-' + rootdir_arr[i].split('\\\\')[-1] + '_method.csv')\n",
    "            shutil.copy('MoJo_1.2.1/' + project_name + '/' + project_name + '_results.txt' , 'Final_Results/' + project_name)\n",
    "            shutil.copy(project_name + '-' + rootdir_arr[i].split('\\\\')[-1] +  '_class.csv' , 'Final_Results/' + project_name)\n",
    "            shutil.copy(project_name + '-' + rootdir_arr[i].split('\\\\')[-1] + '_field.csv' , 'Final_Results/' + project_name)\n",
    "            shutil.copy(project_name + '-' + rootdir_arr[i].split('\\\\')[-1] + '_method.csv' , 'Final_Results/' + project_name)\n",
    "            os.remove(project_name + '-' + rootdir_arr[i].split('\\\\')[-1] +  '_class.csv')\n",
    "            os.remove(project_name + '-' + rootdir_arr[i].split('\\\\')[-1] + '_field.csv')\n",
    "            os.remove(project_name + '-' + rootdir_arr[i].split('\\\\')[-1] + '_method.csv')\n",
    "\n",
    "\n",
    "        #command = 'cd C:/Users/user/Desktop/FIT4003/ & ' + 'java -jar ck-0.3.3-SNAPSHOT-jar-with-dependencies.jar ' + rootdir_arr[-1]\n",
    "        #print(command)\n",
    "        ##os.system('cd C:/Users/user/Desktop/FIT4003/MoJo_1.2.1 & java MoJo test/test2_a.rsf test/test2_b.rsf > test/test_results.txt')\n",
    "        #os.system(command)\n",
    "        #import shutil\n",
    "        #os.mkdir('Final_Results/' + project_name)\n",
    "        #os.rename('class.csv', project_name + '_class.csv')\n",
    "        #os.rename('field.csv', project_name + '_field.csv')\n",
    "        #os.rename('method.csv', project_name + '_method.csv')\n",
    "        #shutil.copy('MoJo_1.2.1/' + project_name + '/' + project_name + '_results.txt' , 'Final_Results/' + project_name)\n",
    "        #shutil.copy(project_name + '_class.csv' , 'Final_Results/' + project_name)\n",
    "        #shutil.copy(project_name + '_field.csv' , 'Final_Results/' + project_name)\n",
    "        #shutil.copy(project_name + '_method.csv' , 'Final_Results/' + project_name)\n",
    "        #os.remove(project_name + '_class.csv')\n",
    "        #os.remove(project_name + '_field.csv')\n",
    "        #os.remove(project_name + '_method.csv')\n",
    "\n",
    "\n",
    "        f = open('Final_Results/' + project_name + '/num_class.txt', 'w')\n",
    "        f.write(str(max_len_tmp))\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(project_name + ' failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\FIT4003'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'airbnb_lottie-android'\n",
    "link = open(project_name + '.txt')\n",
    "for line in link:\n",
    "    link_str = line\n",
    "\n",
    "print(link_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in rootdir_arr:\n",
    "    print(element.split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_name_dict[str(len(json_name_dict)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Final_Results/' + project_name + '/num_class.txt', 'w')\n",
    "f.write(str(max_len_tmp))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(max_len_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import jellyfish\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from zipfile import ZipFile\n",
    "from filecmp import dircmp\n",
    "\n",
    "project_name = 'airbnblottie'\n",
    "rootdir = 'raw_sourcecode'\n",
    "dir_arr = []\n",
    "rootdir_arr = []\n",
    "depth=2\n",
    "\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    if root.count(os.sep) == depth and project_name in str(root):\n",
    "        #print(root)\n",
    "        dir_arr.append(root)\n",
    "        rootdir_arr.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Final_Results/' + project_name)\n",
    "for i in range(11,21):\n",
    "    print(rootdir_arr[i])\n",
    "    command = 'cd C:/Users/tanji/Desktop/FIT4003/ & ' + 'java -jar ck-0.3.3-SNAPSHOT-jar-with-dependencies.jar ' + rootdir_arr[i]\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "    import shutil\n",
    "    #os.mkdir('Final_Results/' + project_name)\n",
    "    os.rename('class.csv', project_name + '-' + rootdir_arr[i] +  '_class.csv')\n",
    "    os.rename('field.csv', project_name + '-' + rootdir_arr[i] + '_field.csv')\n",
    "    os.rename('method.csv', project_name + '-' + rootdir_arr[i] + '_method.csv')\n",
    "    shutil.copy('MoJo_1.2.1/' + project_name + '/' + project_name + '_results.txt' , 'Final_Results/' + project_name)\n",
    "    shutil.copy(project_name + '-' + rootdir_arr[i] +  '_class.csv' , 'Final_Results/' + project_name)\n",
    "    shutil.copy(project_name + '-' + rootdir_arr[i] + '_field.csv' , 'Final_Results/' + project_name)\n",
    "    shutil.copy(project_name + '-' + rootdir_arr[i] + '_method.csv' , 'Final_Results/' + project_name)\n",
    "    os.remove(project_name + '-' + rootdir_arr[i] +  '_class.csv')\n",
    "    os.remove(project_name + '-' + rootdir_arr[i] + '_field.csv')\n",
    "    os.remove(project_name + '-' + rootdir_arr[i] + '_method.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd C:/Users/tanji/Desktop/FIT4003/ & ' + 'java -jar ck-0.3.3-SNAPSHOT-jar-with-dependencies.jar ' + rootdir_arr[-1]\n",
    "print(command)\n",
    "#os.system('cd C:/Users/tanji/Desktop/FIT4003/MoJo_1.2.1 & java MoJo test/test2_a.rsf test/test2_b.rsf > test/test_results.txt')\n",
    "#os.system(command)\n",
    "import shutil\n",
    "#os.mkdir('Final_Results/' + project_name)\n",
    "#os.rename('class.csv', project_name + '_class.csv')\n",
    "#os.rename('field.csv', project_name + '_field.csv')\n",
    "#os.rename('method.csv', project_name + '_method.csv')\n",
    "#shutil.copy('MoJo_1.2.1/' + project_name + '/' + project_name + '_results.txt' , 'Final_Results/' + project_name)\n",
    "#shutil.copy(project_name + '_class.csv' , 'Final_Results/' + project_name)\n",
    "#shutil.copy(project_name + '_field.csv' , 'Final_Results/' + project_name)\n",
    "#shutil.copy(project_name + '_method.csv' , 'Final_Results/' + project_name)\n",
    "#os.remove(project_name + '_class.csv')\n",
    "#os.remove(project_name + '_field.csv')\n",
    "#os.remove(project_name + '_method.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "link.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Final_Results/' + project_name + '/num_class.txt', 'w')\n",
    "f.write(str(max_len_tmp))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airbnb-lottie-android'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
